# Fun With Spark

Parallel computation is one of the easiest ways to throw computational power at a problem. Technological development has made it cheaper and cheaper to 

A long time ago [PiCloud](https://www.wired.com/2013/11/dropbox-piclou/) made access to "effectively unlimited" parallel computation (on Amazon Web Service Service)astonishingly easy from Python. 

Unfortunately their business model did not appear sustainable, and I havev found no equivalent that combined the power and ease of use. There are plenty of powerful ways to set up a grid and interface, but they require lots of skilled effort. PiCloud was painless. 

I'm hoping Spark will turn out to be the near-next-best thing. It's survived the rough "3-year over-hype" period, so I think it's around to stay. Let's see what we can do with it. This repo is my "sandbox" to answer that question. 

